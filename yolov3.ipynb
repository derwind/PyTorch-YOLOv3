{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"yolov3.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"14GPPNgMkZRYrpQddnV3o4k4RDke_L5Tl","authorship_tag":"ABX9TyM86a2TTsQKDeoPZECrZ0TE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["! cd /content/drive/MyDrive/Colab\\ Notebooks && git clone https://github.com/eriklindernoren/PyTorch-YOLOv3.git"],"metadata":{"id":"PiCYHXB33p8P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! pip install terminaltables imgaug==\"0.4.0\""],"metadata":{"id":"eev-XhKc4cIo"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3mT7CP2h3RfB"},"outputs":[],"source":["import os\n","os.chdir('/content/drive/MyDrive/Colab Notebooks/PyTorch-YOLOv3')"]},{"cell_type":"markdown","source":["# download pre-trained weights"],"metadata":{"id":"4Y6hR4L4KoLJ"}},{"cell_type":"code","source":["! cd weights && sh download_weights.sh"],"metadata":{"id":"4at-vKQU5afN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# parameter settings"],"metadata":{"id":"p-4J53hwKwv0"}},{"cell_type":"code","source":["import numpy as np\n","from PIL import Image\n","import torch\n","from torch.autograd import Variable\n","import torchvision.transforms as transforms\n","\n","from pytorchyolo.utils.transforms import Resize, DEFAULT_TRANSFORMS"],"metadata":{"id":"V8waGoH3-BsG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_path = 'config/yolov3.cfg'\n","weights_path = 'weights/yolov3.weights'\n","classes = 'data/coco.names'\n","output = 'output'\n","batch_size = 1\n","img_size = 416\n","n_cpu = 8\n","conf_thres = 0.5\n","nms_thres = 0.4"],"metadata":{"id":"7PM5gvuZ63V9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# prepare image data"],"metadata":{"id":"jZP65QpTEhu5"}},{"cell_type":"code","source":["img_path = 'data/samples/dog.jpg'\n","\n","img = np.array(Image.open(img_path).convert('RGB'), dtype=np.uint8)\n","boxes = np.zeros((1, 5))\n","transform=transforms.Compose([DEFAULT_TRANSFORMS, Resize(img_size)])\n","\n","img, _ = transform((img, boxes))"],"metadata":{"id":"cfCTyvQ18RgU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tensor2im(img_tensor):\n","    # dimension: CHW -> HWC\n","    img = img_tensor.numpy().transpose(1, 2, 0)\n","    img = np.asarray(img*255, dtype=np.uint8)\n","    # ensure memory contiguity\n","    return np.ascontiguousarray(img)\n","\n","Image.frombuffer('RGB', (img_size, img_size), tensor2im(img))"],"metadata":{"id":"haWZpp40-_Fw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# extract `detect_directory` function and detect objects step by step"],"metadata":{"id":"d0KOhFJ8ExLH"}},{"cell_type":"code","source":["from pytorchyolo.models import load_model\n","from pytorchyolo.utils.utils import load_classes, rescale_boxes, non_max_suppression"],"metadata":{"id":"Cwz4w_YrEo4t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classes = load_classes(classes)\n","model = load_model(model_path, weights_path)"],"metadata":{"id":"TWMZoxIO_Ach"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model"],"metadata":{"id":"pEEh4DytFMst"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","\n","Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n","\n","input_img = Variable(img.type(Tensor))\n","input_img = torch.unsqueeze(input_img, 0)\n","\n","with torch.no_grad():\n","    detections = model(input_img)\n","    detections = non_max_suppression(detections, conf_thres, nms_thres)\n","    if len(detections) == 1:\n","        detections = detections[0]"],"metadata":{"id":"5qv2siSoFbLu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Visualization for detection results"],"metadata":{"id":"iPfUyC-nHZCt"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import random\n","\n","# Create plot\n","img = np.array(Image.open(img_path))\n","plt.figure()\n","fig, ax = plt.subplots(1)\n","ax.imshow(img)\n","# Rescale boxes to original image\n","detections = rescale_boxes(detections, img_size, img.shape[:2])\n","unique_labels = detections[:, -1].cpu().unique()\n","n_cls_preds = len(unique_labels)\n","# Bounding-box colors\n","cmap = plt.get_cmap(\"tab20b\")\n","colors = [cmap(i) for i in np.linspace(0, 1, n_cls_preds)]\n","bbox_colors = random.sample(colors, n_cls_preds)\n","for x1, y1, x2, y2, conf, cls_pred in detections:\n","\n","    print(f\"\\t+ Label: {classes[int(cls_pred)]} | Confidence: {conf.item():0.4f}\")\n","\n","    box_w = x2 - x1\n","    box_h = y2 - y1\n","\n","    color = bbox_colors[int(np.where(unique_labels == int(cls_pred))[0])]\n","    # Create a Rectangle patch\n","    bbox = patches.Rectangle((x1, y1), box_w, box_h, linewidth=2, edgecolor=color, facecolor=\"none\")\n","    # Add the bbox to the plot\n","    ax.add_patch(bbox)\n","    # Add label\n","    plt.text(\n","        x1,\n","        y1,\n","        s=classes[int(cls_pred)],\n","        color=\"white\",\n","        verticalalignment=\"top\",\n","        bbox={\"color\": color, \"pad\": 0})"],"metadata":{"id":"mDAOc0HaGkXW"},"execution_count":null,"outputs":[]}]}